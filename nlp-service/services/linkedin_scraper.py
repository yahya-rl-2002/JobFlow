import logging
from typing import List, Dict, Optional
from datetime import datetime
# Utiliser le scraper BeautifulSoup qui est plus fiable
from services.job_scraper import JobScraper

logger = logging.getLogger(__name__)

class LinkedInScraper:
    """
    Service de scraping LinkedIn utilisant BeautifulSoup
    pour r√©cup√©rer de VRAIES offres bas√©es sur les crit√®res utilisateurs.
    """

    def scrape_jobs(
        self,
        keywords: str,
        location: str = '',
        limit: int = 25,
        site_name: str = 'linkedin'
    ) -> List[Dict]:
        """
        Scrape les offres via BeautifulSoup en respectant les crit√®res
        """
        try:
            logger.info(f'üîç Scraping {site_name}: "{keywords}" in "{location}" (Limit: {limit})')
            
            # Utiliser le scraper BeautifulSoup existant
            scraper = JobScraper()
            
            if site_name == 'linkedin':
                jobs = scraper.scrape_linkedin(
                    keywords=keywords,
                    location=location,
                    limit=limit
                )
            elif site_name == 'indeed':
                jobs = scraper.scrape_indeed(
                    keywords=keywords,
                    location=location,
                    limit=limit
                )
            else:
                # Par d√©faut, essayer LinkedIn
                jobs = scraper.scrape_linkedin(
                    keywords=keywords,
                    location=location,
                    limit=limit
                )
            
            # Filtrer les offres avec URLs valides
            valid_jobs = []
            for job in jobs:
                if job.get('url') and ('linkedin.com' in job['url'] or 'indeed.com' in job['url']):
                    valid_jobs.append(job)
                elif job.get('url'):
                    # URL valide mais pas LinkedIn/Indeed, on l'accepte quand m√™me
                    valid_jobs.append(job)
            
            if len(valid_jobs) == 0:
                logger.warning(f"‚ùå Aucune offre valide trouv√©e pour '{keywords}' dans '{location}'")
                logger.info("üí° LinkedIn peut bloquer les requ√™tes. Essayez avec d'autres crit√®res ou configurez des proxies.")
                return []
            
            logger.info(f"‚úÖ Found {len(valid_jobs)} valid jobs with URLs")
            return valid_jobs[:limit]
            
        except Exception as e:
            logger.error(f'üî• Critical Error in scraping: {str(e)}', exc_info=True)
            # Ne pas retourner de d√©mos, retourner un tableau vide
            return []
